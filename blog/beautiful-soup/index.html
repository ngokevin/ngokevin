<html>
  <head>
    <title>Kevin Ngo</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Earlier, I wrote a post about having to populate a table with contact information for network administrators for secure VLANs. I had to do some housekeeping on our crusty database schema using...">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="ngokevin.com">
    <meta name="twitter:creator" content="Kevin Ngo">
    <meta name="twitter:title" content="Beautiful Soup is Beautiful">
    <meta name="twitter:description" content="Earlier, I wrote a post about having to populate a table with contact information for network administrators for secure VLANs. I had to do some housekeeping on our crusty database schema using...">
    <meta name="twitter:image" content="http://www.crummy.com/software/BeautifulSoup/10.1.jpg">
    <link rel="stylesheet" href="/css/base.css">
    
     <link rel="stylesheet" href="/css/post.css"> 
    <script src="https://use.fontawesome.com/5b235cd0cb.js"></script>
  <link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>
  <body>
    <div class="post">
  
    <a href="/">&laquo; Kevin Ngo</a>
  

  <h1>Beautiful Soup is Beautiful</h1>
  <p>15 Dec 2011</p>

  
    <img src="http://www.crummy.com/software/BeautifulSoup/10.1.jpg">
  

  <p>Earlier, I wrote a <a href="http://ngokevin.com/blog/20111215-sqlalchemy/">post</a> about
having to populate a table with contact information for network administrators
for secure VLANs. I had to do some housekeeping on our crusty database schema
using SQLAlchemy to accomodate a couple of new tables. Now, it was time to
populate the new firewall contact information table. A lot of the contact
information could be found on an intranet site in a nice, neat, and most
importantly scrapable table. Previously, I had been using either flat regex or
lxml to scrape web pages, but now it was time to play it smart and have a slurp
of some <a href="www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a>, a Python HTML
parser for screen-scraping.</p>
<hr>
<p>I had heard about Beautiful Soup before, but I had never gotten around to
actually playing with it. I was trying out lxml but was put off by its
confusing documentation and focus on XML rather than HTML. Boy am I glad that I
tried Beautiful Soup. It makes parsing HTML as easy as navigating through the
DOM in Javascript in terms of their similar APIs.</p>
<p>Obviously, I first had to make a request to the intranet site, which required
authentication. Then I had to throw that HTML response into the stew so I could
serve some delicious soup:</p>
<pre><code>import urllib2
import base64

opener = urllib2.build_opener()
request = urllib2.Request(&quot;http://intranet.net.oregonstate.edu/private/firewall-contexts.php&quot;)

# authenticate
base64string = base64.encodestring(&#39;username:password&#39;)[:-1]
request.add_header(&quot;Authorization&quot;, &quot;Basic %s&quot; % base64string)

# request and convert to document tree
response = opener.open(request)
html = response.read()
soup = BeautifulSoup(html)
</code></pre><p>Here’s where it gets even easier. I simply needed to extract information from a
table. So I grabbed the table, grabbed the rows from the table, and iterated
through the rows. What was funny was that this old website had two HTML elements.</p>
<pre><code># get rows from content table
content = soup.findAll(&#39;html&#39;)[1] # page has two html elements
table = content.table
rows = table.findAll(&#39;tr&#39;)[1:] # ignore table header row

for row in rows:
    firewall_contact = {}
    tds = row.findAll(&#39;td&#39;)

    # parse firewall context name
    context = tds[0].findAll(text=True)[0]

    # parse description
    description = tds[1].findAll(text=True)[0]

    # parse administrators
    try:
        administrators = tds[2].findAll(text=True)[0].split(&#39;,&#39;)
    except IndexError:
        pass
</code></pre><p>What was also funny was that some of the names in the table weren’t their given
names. I needed the exact name so I could query for their contact information
in LDAP so I wrote a silly hard-coded function that translated names like Andy
to Andrew.</p>
<pre><code>    # lookup adminstrator contact information from ldap
    info = None
    for administrator in administrators:
        name = full(administrator.strip()).split(&#39; &#39;)
        if len(name) == 2:
            info = ldap_search(first_name=name[0], last_name=name[1])
            if not info:
                info = ldap_search(first_name=full(name[0]), last_name=name[1])
            if not info:
                info = ldap_search(first_name=full(name[0], alt=True), last_name=name[1])
            if not info:
                continue
            break
        else:
            continue
</code></pre><p>Then I just parsed the rest, threw them into a list of dictionaries, and
returned them for SQLAlchemy to have its way with them dictionaries. Nothing
like Alchemizing some Beautiful Soup in a stirring cauldron on a cold evening.</p>
<pre><code># parse vlan ids
    vlans = []
    vlan_texts = tds[3].findAll(text=True)
    for vlan_text in vlan_texts:
        try:
            matches = vlan_regex.findall(vlan_text)[0]
            for match in matches:
                if match:
                    vlans.append(match)
        except IndexError:
            pass

    # add firewall contact to list of firewall contacts
    for vlan in vlans:
        firewall_contact = {}
        firewall_contact[&#39;context&#39;] = context
        firewall_contact[&#39;description&#39;] = description
        firewall_contact[&#39;vlan_id&#39;] = vlan
        get_ldap_info(info, firewall_contact)
        if not &#39;name&#39; in firewall_contact:
            firewall_contact[&#39;name&#39;] = administrators[0]
        firewall_contacts.append(firewall_contact)

return firewall_contacts
</code></pre><p>If I ever have to screen-scrape flat HTML pages again, Beautiful Soup will be
my go-to parser.</p>

</div>


    <div class="social">
      <a href="https://github.com/ngokevin/"><i class="fa fa-github-alt" aria-hidden="true"></i></a>
      <a href="https://twitter.com/andgokevin/"><i class="fa fa-twitter" aria-hidden="true"></i></a>
      <a href="https://instagram.com/andgokevin/"><i class="fa fa-instagram" aria-hidden="true"></i></a>
    </div>

    <script src="https://cdn.jsdelivr.net/blazy/1.8.2/blazy.min.js"></script>
    <script>new Blazy({selector: '.lazyload'});</script>
  </body>
</html>
